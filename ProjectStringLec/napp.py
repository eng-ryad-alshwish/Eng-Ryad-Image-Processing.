import streamlit as st
import cv2
import numpy as np
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase
from PIL import Image
import time
import os
from io import BytesIO

st.set_page_config(
    page_title="ğŸ¥ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„Ø§ØªØ± Ø§Ù„Ø­ÙŠ",
    page_icon="ğŸ¥",
    layout="wide"
)

# Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­ÙØ¸
SAVE_DIR = "saved_images"
os.makedirs(SAVE_DIR, exist_ok=True)

# ØªØ¹Ø±ÙŠÙ Ø§Ù„ÙÙ„Ø§ØªØ±
def apply_grayscale(frame):
    return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

def apply_gaussian_blur(frame):
    return cv2.GaussianBlur(frame, (15, 15), 0)

def apply_edge_detection(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 100, 200)
    return cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)

def apply_sepia(frame):
    kernel = np.array([[0.272, 0.534, 0.131],
                       [0.349, 0.686, 0.168],
                       [0.393, 0.769, 0.189]])
    frame = cv2.transform(frame, kernel)
    return np.clip(frame, 0, 255).astype(np.uint8)

def apply_invert(frame):
    return cv2.bitwise_not(frame)

def apply_sketch(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    inv_gray = 255 - gray
    blur = cv2.GaussianBlur(inv_gray, (21, 21), 0)
    sketch = cv2.divide(gray, 255 - blur, scale=256)
    return cv2.cvtColor(sketch, cv2.COLOR_GRAY2BGR)

def apply_emboss(frame):
    kernel = np.array([[-2, -1, 0],
                       [-1, 1, 1],
                       [0, 1, 2]])
    return cv2.filter2D(frame, -1, kernel)

# Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ÙÙ„Ø§ØªØ±
filter_options = {
    "Ø¨Ø¯ÙˆÙ† ÙÙ„ØªØ±": None,
    "ØªØ¯Ø±Ø¬ Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ": apply_grayscale,
    "ØªÙ…ÙˆÙŠÙ‡ Gaussian": apply_gaussian_blur,
    "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù": apply_edge_detection,
    "Ù„ÙˆÙ† Ø³ÙŠØ¨ÙŠØ§": apply_sepia,
    "Ø¹ÙƒØ³ Ø§Ù„Ø£Ù„ÙˆØ§Ù†": apply_invert,
    "Ø±Ø³Ù… Ù‚Ù„Ù… Ø±ØµØ§Øµ": apply_sketch,
    "Ù†Ù‚Ø´ Ø¨Ø§Ø±Ø²": apply_emboss
}

# Sidebar
with st.sidebar:
    st.title("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙÙ„Ø§ØªØ±")
    st.session_state.selected_filter = st.radio("Ø§Ø®ØªØ± Ø§Ù„ÙÙ„ØªØ±:", list(filter_options.keys()))
    if 'capture_next' not in st.session_state:
        st.session_state.capture_next = False
        st.session_state.captured_image = None
    capture_btn = st.button("Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© ğŸ“¸")

# Video Processor
class VideoProcessor(VideoProcessorBase):
    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù…Ù† session_state
        selected_filter = st.session_state.selected_filter
        if selected_filter != "Ø¨Ø¯ÙˆÙ† ÙÙ„ØªØ±":
            filtered = filter_options[selected_filter](img)
            if len(filtered.shape) == 2:  # grayscale
                filtered = cv2.cvtColor(filtered, cv2.COLOR_GRAY2BGR)
        else:
            filtered = img

        # Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨
        if st.session_state.capture_next:
            st.session_state.captured_image = cv2.cvtColor(filtered, cv2.COLOR_BGR2RGB)
            st.session_state.capture_next = False

        return filtered

# ØªØ´ØºÙŠÙ„ WebRTC
ctx = webrtc_streamer(
    key="example",
    video_processor_factory=VideoProcessor,
    media_stream_constraints={"video": True, "audio": False},
    async_processing=True
)

# Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„ØµÙˆØ±Ø©
if capture_btn and ctx.video_processor:
    st.session_state.capture_next = True

# Ø¹Ø±Ø¶ ÙˆØ­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ù„ØªÙ‚Ø·Ø©
if st.session_state.captured_image is not None:
    st.image(st.session_state.captured_image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ù„ØªÙ‚Ø·Ø©", use_column_width=True)
    buf = BytesIO()
    Image.fromarray(st.session_state.captured_image).save(buf, format="JPEG")
    buf.seek(0)
    st.download_button(
        "ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©",
        buf,
        file_name=f"captured_{int(time.time())}.jpg",
        mime="image/jpeg"
    )
